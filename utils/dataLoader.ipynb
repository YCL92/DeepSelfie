{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# mass includes\n",
    "import os, sys\n",
    "import cv2\n",
    "import pickle\n",
    "import rawpy as rp\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from torch.utils import data\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Dataset for r2rNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class r2rSet(data.Dataset):\n",
    "    def __init__(self, opt, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.data_root = os.path.join(opt.data_root, self.mode)\n",
    "        self.r2r_size = opt.r2r_size\n",
    "        self.file_list = [\n",
    "            file for file in os.listdir(self.data_root) if '.pkl' in file\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load a new sample\n",
    "        with open(os.path.join(self.data_root, self.file_list[index]),\n",
    "                  'rb') as file:\n",
    "            data_dict = pickle.load(file)\n",
    "\n",
    "        # read from file\n",
    "        raw_data = data_dict['raw'].astype(np.float32)\n",
    "        srgb_data = data_dict['img'].astype(np.float32)\n",
    "        blk_level = data_dict['blk_level'].astype(np.float32)\n",
    "        sat_level = data_dict['sat_level'].astype(np.float32)\n",
    "        cam_wb = data_dict['cam_wb'].astype(np.float32)\n",
    "\n",
    "        # random transforms\n",
    "        if self.mode == 'train':\n",
    "            # random crop\n",
    "            crop_h = np.random.randint(0, raw_data.shape[1] - self.r2r_size)\n",
    "            crop_w = np.random.randint(0, raw_data.shape[2] - self.r2r_size)\n",
    "            raw_patch = raw_data[:, crop_h:crop_h + self.r2r_size,\n",
    "                                 crop_w:crop_w + self.r2r_size]\n",
    "            srgb_patch = srgb_data[:, 2 * crop_h:2 * (crop_h + self.r2r_size),\n",
    "                                   2 * crop_w:2 * (crop_w + self.r2r_size)]\n",
    "        else:\n",
    "            raw_patch = raw_data[:, :, :]\n",
    "            srgb_patch = srgb_data[:, :, :]\n",
    "\n",
    "        # normalization\n",
    "        raw_patch = np.clip((raw_patch - np.resize(blk_level, [4, 1, 1])) /\n",
    "                            (sat_level - np.resize(blk_level, [4, 1, 1])), 0.0,\n",
    "                            1.0)\n",
    "        srgb_patch = srgb_patch / 65535.0\n",
    "\n",
    "        # to pyTorch tensor\n",
    "        raw_patch = t.from_numpy(raw_patch)\n",
    "        srgb_patch = t.from_numpy(srgb_patch)\n",
    "        cam_wb = t.from_numpy(cam_wb).view([3, 1, 1])\n",
    "        if self.mode == 'train':\n",
    "            cam_wb = cam_wb.expand([3, self.r2r_size, self.r2r_size])\n",
    "        else:\n",
    "            cam_wb = cam_wb.expand([3, raw_patch.size(1), raw_patch.size(2)])\n",
    "\n",
    "        return raw_patch, srgb_patch, cam_wb\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset for fivekNight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     31,
     69,
     123
    ]
   },
   "outputs": [],
   "source": [
    "# random cropping and flipping\n",
    "def randTransform(bg_img, fg_img, mask, img_size):\n",
    "    # cropping\n",
    "    if bg_img.shape[1] > bg_img.shape[0]:\n",
    "        crop_h = np.random.randint(img_size[1], bg_img.shape[0])\n",
    "        crop_w = np.round(crop_h / 0.75)\n",
    "    else:\n",
    "        crop_w = np.random.randint(img_size[0], bg_img.shape[1])\n",
    "        crop_h = np.round(crop_w / 1.33)\n",
    "    crop_y = int(np.random.randint(0, bg_img.shape[0] - crop_h))\n",
    "    crop_x = int(np.random.randint(0, bg_img.shape[1] - crop_w))\n",
    "    crop_h = int(crop_h)\n",
    "    crop_w = int(crop_w)\n",
    "    bg_img = bg_img[crop_y:crop_y + crop_h, crop_x:crop_x + crop_w, :]\n",
    "\n",
    "    # flipping\n",
    "    rand_var = np.random.rand()\n",
    "    if rand_var < 0.25:\n",
    "        bg_img = cv2.flip(bg_img, 1)\n",
    "    elif rand_var < 0.5:\n",
    "        fg_img = cv2.flip(fg_img, 1)\n",
    "        mask = cv2.flip(mask, 1)\n",
    "    elif rand_var < 0.75:\n",
    "        bg_img = cv2.flip(bg_img, 1)\n",
    "        fg_img = cv2.flip(fg_img, 1)\n",
    "        mask = cv2.flip(mask, 1)\n",
    "\n",
    "    return bg_img, fg_img, mask\n",
    "\n",
    "\n",
    "# image blending and rescaling\n",
    "def imgBlend(bg_img, fg_img, mask, img_size):\n",
    "    # scaling\n",
    "    scale = np.random.uniform(0.5, 1.0) * np.minimum(\n",
    "        bg_img.shape[0] / mask.shape[0], bg_img.shape[1] / mask.shape[1])\n",
    "    offset = np.random.randint(0, bg_img.shape[1] - int(scale * mask.shape[1]))\n",
    "    mask = cv2.resize(mask,\n",
    "                      None,\n",
    "                      fx=scale,\n",
    "                      fy=scale,\n",
    "                      interpolation=cv2.INTER_CUBIC)\n",
    "    fg_img = cv2.resize(fg_img,\n",
    "                        None,\n",
    "                        fx=scale,\n",
    "                        fy=scale,\n",
    "                        interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # paste crop image to an empty image\n",
    "    syth_mask = np.zeros((bg_img.shape[0], bg_img.shape[1]), dtype=np.float32)\n",
    "    syth_mask[bg_img.shape[0] - mask.shape[0]:bg_img.shape[0],\n",
    "              offset:offset + mask.shape[1]] = mask\n",
    "    syth_mask = np.repeat(syth_mask[:, :, np.newaxis], 3, axis=2) / 255.0\n",
    "    syth_img = np.zeros((bg_img.shape[0], bg_img.shape[1], 3),\n",
    "                        dtype=np.float32)\n",
    "    syth_img[bg_img.shape[0] - mask.shape[0]:bg_img.shape[0],\n",
    "             offset:offset + mask.shape[1], :] = fg_img\n",
    "    syth_img = (syth_mask * syth_img + (1 - syth_mask) * bg_img) / 65535.0\n",
    "\n",
    "    # resize to fixed shape\n",
    "    syth_img = cv2.resize(syth_img, img_size, interpolation=cv2.INTER_CUBIC)\n",
    "    syth_mask = cv2.resize(syth_mask, img_size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # clip to 0-1\n",
    "    syth_img = np.clip(syth_img, 0.0, 1.0)\n",
    "    syth_mask = np.clip(syth_mask, 0.0, 1.0)\n",
    "\n",
    "    return syth_img, syth_mask\n",
    "\n",
    "\n",
    "class fivekNight(data.Dataset):\n",
    "    def __init__(self, opt):\n",
    "        # get sample list\n",
    "        self.img_size = opt.isp_size\n",
    "        self.bg_path = os.path.join(opt.data_root, 'scene')\n",
    "        self.fg_path = os.path.join(opt.data_root, 'people')\n",
    "        self.bg_list = [\n",
    "            file[:-4] for file in os.listdir(os.path.join(self.bg_path, 'raw'))\n",
    "            if '.png' in file\n",
    "        ]\n",
    "        self.fg_list = [\n",
    "            file[:-4] for file in os.listdir(os.path.join(self.fg_path, 'raw'))\n",
    "            if '.png' in file\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # read images and mask\n",
    "        bg_index = int(index // len(self.fg_list))\n",
    "        fg_index = int(index % len(self.fg_list))\n",
    "        bg_img = cv2.imread(\n",
    "            os.path.join(self.bg_path, 'raw', self.bg_list[bg_index] + '.png'),\n",
    "            cv2.IMREAD_UNCHANGED)\n",
    "        fg_img = cv2.imread(\n",
    "            os.path.join(self.fg_path, 'raw', self.fg_list[fg_index] + '.png'),\n",
    "            cv2.IMREAD_UNCHANGED)\n",
    "        with open(\n",
    "                os.path.join(self.fg_path, 'mask',\n",
    "                             self.fg_list[fg_index] + '.pkl'), 'rb') as pkl:\n",
    "            mask = pickle.load(pkl)\n",
    "\n",
    "        # BGR to RGB\n",
    "        bg_img = cv2.cvtColor(bg_img, cv2.COLOR_BGR2RGB)\n",
    "        fg_img = cv2.cvtColor(fg_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # random transforms\n",
    "        bg_img, fg_img, mask = randTransform(bg_img, fg_img, mask,\n",
    "                                             self.img_size)\n",
    "\n",
    "        # image blending and rescaling\n",
    "        syth_img, syth_mask = imgBlend(bg_img, fg_img, mask, self.img_size)\n",
    "\n",
    "        # convert to tensor and normalize\n",
    "        syth_img = t.tensor(syth_img, dtype=t.float).permute(2, 0, 1)\n",
    "        syth_mask = t.tensor(np.stack(\n",
    "            [syth_mask[:, :, 0], 1.0 - syth_mask[:, :, 0]], axis=0),\n",
    "                             dtype=t.float)\n",
    "\n",
    "        return syth_img, syth_mask\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.fg_list) * len(self.bg_list)\n",
    "\n",
    "\n",
    "class valSet(data.Dataset):\n",
    "    def __init__(self, opt):\n",
    "        self.data_root = os.path.join(opt.data_root,\n",
    "                                      'val%d' % opt.amp_range[1])\n",
    "        self.file_list = [\n",
    "            file for file in os.listdir(self.data_root) if '.pkl' in file\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load a new sample\n",
    "        with open(os.path.join(self.data_root, self.file_list[index]),\n",
    "                  'rb') as file:\n",
    "            data_dict = pickle.load(file)\n",
    "\n",
    "        # read from file\n",
    "        syth_img = data_dict['syth_img']\n",
    "        thumb_img = data_dict['thumb_img']\n",
    "        struct_img = data_dict['struct_img']\n",
    "        seg_mask = data_dict['seg_mask']\n",
    "        amp = data_dict['amp']\n",
    "        noisy_raw = data_dict['noisy_raw']\n",
    "        sorted_mask = data_dict['sorted_mask']\n",
    "        wb = data_dict['wb']\n",
    "\n",
    "        return syth_img, thumb_img, struct_img, seg_mask, amp, noisy_raw, sorted_mask, wb\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.file_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
