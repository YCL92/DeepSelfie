{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Useful Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mass includes\n",
    "import torch as t\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual post-process of raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     11,
     20,
     31,
     51
    ]
   },
   "outputs": [],
   "source": [
    "# convert RAW to sRGB image\n",
    "def raw2Img(raw_data, wb, cam_matrix):\n",
    "    raw_data = applyWB(raw_data, wb)\n",
    "    img = demosaic(raw_data)\n",
    "    img = cam2sRGB(img, cam_matrix)\n",
    "    img = applyGamma(img)\n",
    "\n",
    "    return t.clamp(img, 0.0, 1.0)\n",
    "\n",
    "\n",
    "# apply white balancing\n",
    "def applyWB(raw_data, wb):\n",
    "    raw_out = raw_data.clone()\n",
    "    raw_out[0, :, :] *= wb[0]\n",
    "    raw_out[3, :, :] *= wb[2]\n",
    "\n",
    "    return raw_out\n",
    "\n",
    "\n",
    "# demosaicing\n",
    "def demosaic(raw_data):\n",
    "    _, hei, wid = raw_data.size()\n",
    "    img = raw_data.new_empty([3, hei, wid])\n",
    "    img[0, :, :] = raw_data[0, :, :]  # R\n",
    "    img[1, :, :] = (raw_data[1, :, :] + raw_data[2, :, :]) / 2  # G1+G2\n",
    "    img[2, :, :] = raw_data[3, :, :]  # B\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "# color space conversion\n",
    "def cam2sRGB(img, cam_matrix):\n",
    "    cam_matrix = img.new_tensor(cam_matrix)\n",
    "    xyz_matrix = img.new_tensor([[0.4124564, 0.3575761, 0.1804375],\n",
    "                                 [0.2126729, 0.7151522, 0.0721750],\n",
    "                                 [0.0193339, 0.1191920, 0.9503041]])\n",
    "    trans_matrix = t.matmul(cam_matrix, xyz_matrix)\n",
    "    trans_matrix /= t.sum(trans_matrix, 1, keepdim=True).repeat(1, 3)\n",
    "    trans_matrix = t.inverse(trans_matrix)\n",
    "    new_img = t.empty_like(img)\n",
    "    new_img[0, :, :] = img[0, :, :] * trans_matrix[0, 0] + img[\n",
    "        1, :, :] * trans_matrix[0, 1] + img[2, :, :] * trans_matrix[0, 2]\n",
    "    new_img[1, :, :] = img[0, :, :] * trans_matrix[1, 0] + img[\n",
    "        1, :, :] * trans_matrix[1, 1] + img[2, :, :] * trans_matrix[1, 2]\n",
    "    new_img[2, :, :] = img[0, :, :] * trans_matrix[2, 0] + img[\n",
    "        1, :, :] * trans_matrix[2, 1] + img[2, :, :] * trans_matrix[2, 2]\n",
    "\n",
    "    return new_img\n",
    "\n",
    "\n",
    "# gamma correction\n",
    "def applyGamma(img):\n",
    "    new_img = t.pow(img, 1 / 2.2)\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     13,
     34
    ]
   },
   "outputs": [],
   "source": [
    "# normalization\n",
    "def normalize(raw_data, bk_level, sat_level):\n",
    "    normal_raw = t.empty_like(raw_data)\n",
    "    for index in range(raw_data.size(0)):\n",
    "        for channel in range(raw_data.size(1)):\n",
    "            normal_raw[index, channel, :, :] = (\n",
    "                raw_data[index, channel, :, :] -\n",
    "                bk_level[channel]) / (sat_level - bk_level[channel])\n",
    "\n",
    "    return normal_raw\n",
    "\n",
    "\n",
    "# resize Bayer pattern\n",
    "def downSample(raw_data, struct_img_size):\n",
    "    # convert Bayer pattern to down-sized sRGB image\n",
    "    batch, _, hei, wid = raw_data.size()\n",
    "    raw_img = raw_data.new_empty((batch, 3, hei, wid))\n",
    "    raw_img[:, 0, :, :] = raw_data[:, 0, :, :]  # R\n",
    "    raw_img[:,\n",
    "            1, :, :] = (raw_data[:, 1, :, :] + raw_data[:, 2, :, :]) / 2.0  # G\n",
    "    raw_img[:, 2, :, :] = raw_data[:, 3, :, :]  # B\n",
    "\n",
    "    # down-sample to small size\n",
    "    if hei != struct_img_size[1] and wid != struct_img_size[0]:\n",
    "        raw_img = t.nn.functional.interpolate(raw_img,\n",
    "                                              size=(struct_img_size[1],\n",
    "                                                    struct_img_size[0]),\n",
    "                                              mode='bicubic')\n",
    "    raw_img = t.clamp(raw_img, 0.0, 1.0)\n",
    "\n",
    "    return raw_img\n",
    "\n",
    "\n",
    "# image standardization (mean 0, std 1)\n",
    "def standardize(srgb_img):\n",
    "    struct_img = t.empty_like(srgb_img)\n",
    "    adj_std = 1.0 / t.sqrt(srgb_img.new_tensor(srgb_img[0, :, :, :].numel()))\n",
    "    for index in range(srgb_img.size(0)):\n",
    "        mean = t.mean(srgb_img[index, :, :, :])\n",
    "        std = t.std(srgb_img[index, :, :, :])\n",
    "        adj_std = t.max(std, adj_std)\n",
    "        struct_img[index, :, :, :] = (srgb_img[index, :, :, :] -\n",
    "                                      mean) / adj_std\n",
    "\n",
    "    return struct_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training sample sythesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     11,
     30
    ]
   },
   "outputs": [],
   "source": [
    "# convert sRGB image to RGGB pattern\n",
    "def toRGGB(srgb_img):\n",
    "    rggb_img = t.stack(\n",
    "        (srgb_img[:, 0, 0::2, 0::2], srgb_img[:, 1, 0::2, 1::2],\n",
    "         srgb_img[:, 1, 1::2, 0::2], srgb_img[:, 2, 1::2, 1::2]),\n",
    "        dim=1)\n",
    "\n",
    "    return rggb_img\n",
    "\n",
    "\n",
    "# add noise to Bayer pattern\n",
    "def addPGNoise(raw_data, noise_stat):\n",
    "    # add noise to each sample\n",
    "    noisy_raw = t.empty_like(raw_data)\n",
    "    for index in range(raw_data.size(0)):\n",
    "        log_shot = raw_data.new_empty(1).uniform_(noise_stat['min'],\n",
    "                                                  noise_stat['max'])\n",
    "        log_read = raw_data.new_empty(1).normal_(\n",
    "            mean=noise_stat['slope'] * log_shot.item() + noise_stat['const'],\n",
    "            std=noise_stat['std'])\n",
    "        delta_final = t.sqrt(\n",
    "            t.exp(log_shot) * raw_data[index, :, :, :] + t.exp(log_read))\n",
    "        pg_noise = delta_final * t.randn_like(raw_data[index, :, :, :])\n",
    "        noisy_raw[index, :, :, :] = raw_data[index, :, :, :] + pg_noise\n",
    "    noisy_raw = t.clamp(noisy_raw, 0.0, 1.0)\n",
    "\n",
    "    return noisy_raw\n",
    "\n",
    "\n",
    "# blend weighted fg & bg and convert to Bayer pattern\n",
    "def toRaw(r2rNet, syth_img, syth_mask, opt):\n",
    "    # convert sRGB image to half size RGBG pattern\n",
    "    rggb_raw = toRGGB(syth_img)\n",
    "\n",
    "    # extract saturation mask\n",
    "    sat_mask = rggb_raw.new_tensor(t.mean(rggb_raw, 1, keepdim=True) > 0.95)\n",
    "\n",
    "    #random white balance\n",
    "    batch, _, hei, wid = rggb_raw.size()\n",
    "    wb = rggb_raw.new_empty((batch, 3, hei, wid))\n",
    "    for index in range(0, batch):\n",
    "        wb_r = rggb_raw.new_empty(1).uniform_(opt.wb_stat['min'],\n",
    "                                              opt.wb_stat['max'])\n",
    "        wb_b = rggb_raw.new_empty(1).normal_(\n",
    "            mean=opt.wb_stat['slope'] * wb_r.item() + opt.wb_stat['const'],\n",
    "            std=opt.wb_stat['std'])\n",
    "        wb[index, 0, :, :] = t.exp(wb_r)\n",
    "        wb[index, 1, :, :] = 1.0\n",
    "        wb[index, 2, :, :] = t.exp(wb_b)\n",
    "\n",
    "    # convert to Bayer pattern\n",
    "    with t.no_grad():\n",
    "        org_raw = r2rNet(rggb_raw, wb)\n",
    "        org_raw = t.clamp(org_raw, 0.0, 1.0)\n",
    "\n",
    "\n",
    "# random amplification ratio\n",
    "    sorted_mask = syth_mask.clone()\n",
    "    half_mask = t.nn.functional.interpolate(syth_mask, scale_factor=0.5)\n",
    "    half_mask = t.clamp(half_mask, 0.0, 1.0)\n",
    "    amp = org_raw.new_empty((batch, 2))\n",
    "    clean_raw = t.empty_like(org_raw)\n",
    "    for index in range(0, batch):\n",
    "        amp[index, :] = t.clamp(\n",
    "            syth_img.new_empty((2, )).uniform_(0.0, opt.amp_range[1]), 1.0,\n",
    "            opt.amp_range[1])\n",
    "        clean_raw[index, :, :, :] = half_mask[index, 0, :, :].unsqueeze(\n",
    "            0) * org_raw[index, :, :, :] / amp[index, 0] + half_mask[\n",
    "                index,\n",
    "                1, :, :].unsqueeze(0) * org_raw[index, :, :, :] / amp[index, 1]\n",
    "        if amp[index, 0] < amp[index, 1]:\n",
    "            sorted_mask[index, :, :, :] = t.flip(sorted_mask[index, :, :, :],\n",
    "                                                 [0])\n",
    "\n",
    "    # preserve saturation\n",
    "    clean_raw = t.max(clean_raw, sat_mask)\n",
    "\n",
    "    # add noise\n",
    "    noisy_raw = addPGNoise(clean_raw, opt.noise_stat)\n",
    "\n",
    "    # down-sample to fixed size\n",
    "    thumb_img = downSample(clean_raw, opt.att_size)\n",
    "    struct_img = standardize(thumb_img)\n",
    "    seg_mask = t.nn.functional.interpolate(syth_mask,\n",
    "                                           size=(opt.att_size[1],\n",
    "                                                 opt.att_size[0]))\n",
    "    seg_mask = t.clamp(seg_mask, 0.0, 1.0)\n",
    "\n",
    "    return thumb_img, struct_img, seg_mask, amp, noisy_raw, sorted_mask, wb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     23
    ]
   },
   "outputs": [],
   "source": [
    "class vgg16Loss(t.nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(vgg16Loss, self).__init__()\n",
    "        features = list(tv.models.vgg16(pretrained=True).features)[:23]\n",
    "        self.features = t.nn.ModuleList(features).to(device).eval()\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, pred_img, gt_img):\n",
    "        x = pred_img\n",
    "        y = gt_img\n",
    "        vgg_loss = 0.0\n",
    "\n",
    "        # use outputs of relu1_2, relu2_2, relu3_3, relu4_3 as loss\n",
    "        for index, layer in enumerate(self.features):\n",
    "            x = layer(x)\n",
    "            y = layer(y)\n",
    "            if index in {3, 8, 15, 22}:\n",
    "                vgg_loss += t.nn.functional.mse_loss(x, y)\n",
    "\n",
    "        return vgg_loss / 4.0\n",
    "\n",
    "\n",
    "class imgLoss(t.nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(imgLoss, self).__init__()\n",
    "        self.l2_loss = t.nn.MSELoss()\n",
    "        self.vgg_loss = vgg16Loss(device)\n",
    "\n",
    "    def forward(self, masked_img, fused_img, gt_img):\n",
    "        l2_loss = (self.l2_loss(masked_img, gt_img) +\n",
    "                   self.l2_loss(fused_img, gt_img)) / 2.0\n",
    "        vgg_loss = (self.vgg_loss(masked_img, gt_img) +\n",
    "                    self.vgg_loss(fused_img, gt_img)) / 2.0\n",
    "\n",
    "        return l2_loss + vgg_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
