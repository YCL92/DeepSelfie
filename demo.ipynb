{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# mass includes\n",
    "import os, sys, argparse\n",
    "import numpy as np\n",
    "import pyexiv2 as exiv2\n",
    "import rawpy as rp\n",
    "import torch as t\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     19,
     37,
     62,
     83,
     114,
     176,
     225
    ]
   },
   "outputs": [],
   "source": [
    "class BasicModule(t.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicModule, self).__init__()\n",
    "        self.model_name = str(type(self))\n",
    "\n",
    "    def load(self, root, device=None):\n",
    "        save_list = [\n",
    "            file for file in os.listdir(root)\n",
    "            if file.startswith(self.model_name)\n",
    "        ]\n",
    "        save_list.sort()\n",
    "        file_path = os.path.join(root, save_list[-1])\n",
    "        state_dict = t.load(file_path, map_location=device)\n",
    "        self.load_state_dict(t.load(file_path, map_location=device))\n",
    "        print('Weights loaded: %s' % file_path)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "class channelAtt(BasicModule):\n",
    "    def __init__(self, channels):\n",
    "        super(channelAtt, self).__init__()\n",
    "\n",
    "        # squeeze-excitation layer\n",
    "        self.glb_pool = t.nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.squeeze_excite = t.nn.Sequential(\n",
    "            t.nn.Linear(channels, int(channels / 16)), t.nn.LeakyReLU(0.2),\n",
    "            t.nn.Linear(int(channels / 16), channels), t.nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        scale = self.glb_pool(x)\n",
    "        scale = self.squeeze_excite(scale.squeeze())\n",
    "        x = scale.view((x.size(0), x.size(1), 1, 1)) * x\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class encode(BasicModule):\n",
    "    def __init__(self, in_channels, out_channels, max_pool=True):\n",
    "        super(encode, self).__init__()\n",
    "\n",
    "        # features\n",
    "        if max_pool:\n",
    "            self.features = t.nn.Sequential(\n",
    "                t.nn.MaxPool2d((2, 2)),\n",
    "                t.nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "                t.nn.LeakyReLU(0.2),\n",
    "                t.nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "                channelAtt(out_channels), t.nn.LeakyReLU(0.2))\n",
    "        else:\n",
    "            self.features = t.nn.Sequential(\n",
    "                t.nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "                t.nn.LeakyReLU(0.2),\n",
    "                t.nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "                channelAtt(out_channels), t.nn.LeakyReLU(0.2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class skipConn(BasicModule):\n",
    "    def __init__(self, in_channels, out_channels, avg_pool=True):\n",
    "        super(skipConn, self).__init__()\n",
    "\n",
    "        # features\n",
    "        if avg_pool:\n",
    "            self.features = t.nn.Sequential(\n",
    "                t.nn.AvgPool2d((2, 2)),\n",
    "                t.nn.Conv2d(in_channels, out_channels, 1),\n",
    "                channelAtt(out_channels), t.nn.Tanh())\n",
    "        else:\n",
    "            self.features = t.nn.Sequential(\n",
    "                t.nn.Conv2d(in_channels, out_channels, 1),\n",
    "                channelAtt(out_channels), t.nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class decode(BasicModule):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 inter_channels,\n",
    "                 out_channels,\n",
    "                 up_sample=True):\n",
    "        super(decode, self).__init__()\n",
    "\n",
    "        # features\n",
    "        if up_sample:\n",
    "            self.features = t.nn.Sequential(\n",
    "                t.nn.Conv2d(in_channels, inter_channels, 1),\n",
    "                t.nn.Conv2d(inter_channels, inter_channels, 3, padding=1),\n",
    "                t.nn.LeakyReLU(0.2),\n",
    "                t.nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                t.nn.Conv2d(inter_channels, out_channels, 3, padding=1),\n",
    "                channelAtt(out_channels), t.nn.LeakyReLU(0.2))\n",
    "        else:\n",
    "            self.features = t.nn.Sequential(\n",
    "                t.nn.Conv2d(in_channels, inter_channels, 1),\n",
    "                t.nn.Conv2d(inter_channels, inter_channels, 3, padding=1),\n",
    "                t.nn.LeakyReLU(0.2),\n",
    "                t.nn.Conv2d(inter_channels, out_channels, 3, padding=1),\n",
    "                t.nn.LeakyReLU(0.2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class gainEst(BasicModule):\n",
    "    def __init__(self):\n",
    "        super(gainEst, self).__init__()\n",
    "        self.model_name = 'gainEst'\n",
    "\n",
    "        # encoders\n",
    "        self.head = encode(3, 64, max_pool=False)\n",
    "        self.down1 = encode(64, 96, max_pool=True)\n",
    "        self.down2 = encode(96, 128, max_pool=True)\n",
    "        self.down3 = encode(128, 192, max_pool=True)\n",
    "\n",
    "        # bottleneck\n",
    "        self.bottleneck = t.nn.Sequential(\n",
    "            t.nn.MaxPool2d(2, 2), t.nn.Conv2d(192, 256, 3, padding=1),\n",
    "            t.nn.LeakyReLU(0.2), t.nn.Conv2d(256, 256, 3, padding=1),\n",
    "            t.nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            t.nn.Conv2d(256, 192, 3, padding=1), channelAtt(192),\n",
    "            t.nn.LeakyReLU(0.2))\n",
    "\n",
    "        # decoders\n",
    "        self.up1 = decode(384, 384, 128, up_sample=True)\n",
    "        self.up2 = decode(256, 256, 96, up_sample=True)\n",
    "        self.up3 = decode(192, 192, 64, up_sample=True)\n",
    "        self.seg_out = t.nn.Sequential(decode(128, 128, 64, up_sample=False),\n",
    "                                       t.nn.Conv2d(64, 2, 1))\n",
    "\n",
    "        # external actication\n",
    "        self.sigmoid = t.nn.Sigmoid()\n",
    "\n",
    "        # prediction\n",
    "        self.features = t.nn.Sequential(\n",
    "            t.nn.Conv2d(5, 64, 3, stride=2, padding=1), t.nn.LeakyReLU(0.2),\n",
    "            t.nn.Conv2d(64, 96, 3, stride=2, padding=1), t.nn.LeakyReLU(0.2),\n",
    "            t.nn.Conv2d(96, 128, 3, stride=2, padding=1), t.nn.LeakyReLU(0.2),\n",
    "            t.nn.Conv2d(128, 192, 3, stride=2, padding=1), t.nn.LeakyReLU(0.2),\n",
    "            t.nn.Conv2d(192, 256, 3, stride=2, padding=1), t.nn.LeakyReLU(0.2))\n",
    "        self.amp_out = t.nn.Sequential(t.nn.Linear(8 * 6 * 256,\n",
    "                                                   128), t.nn.LeakyReLU(0.2),\n",
    "                                       t.nn.Linear(128, 64),\n",
    "                                       t.nn.LeakyReLU(0.2), t.nn.Linear(64, 2))\n",
    "\n",
    "    def forward(self, thumb_img, struct_img):\n",
    "        # segmentation\n",
    "        out_head = self.head(struct_img)\n",
    "        out_d1 = self.down1(out_head)\n",
    "        out_d2 = self.down2(out_d1)\n",
    "        out_d3 = self.down3(out_d2)\n",
    "        out_bottleneck = self.bottleneck(out_d3)\n",
    "        out_u1 = self.up1(t.cat([out_d3, out_bottleneck], dim=1))\n",
    "        out_u2 = self.up2(t.cat([out_d2, out_u1], dim=1))\n",
    "        out_u3 = self.up3(t.cat([out_d1, out_u2], dim=1))\n",
    "        out_mask = self.seg_out(t.cat([out_head, out_u3], dim=1))\n",
    "\n",
    "        # prediction\n",
    "        out_features = self.features(\n",
    "            t.cat([thumb_img, self.sigmoid(out_mask)], dim=1))\n",
    "        out_amp = self.amp_out(out_features.view(out_features.size(0), -1))\n",
    "        out_amp = t.clamp(out_amp, 0.0, 1.0)\n",
    "\n",
    "        return out_mask, out_amp\n",
    "\n",
    "\n",
    "class ispNet(BasicModule):\n",
    "    def __init__(self):\n",
    "        super(ispNet, self).__init__()\n",
    "\n",
    "        # encoders\n",
    "        self.head = encode(8, 64, max_pool=False)\n",
    "        self.down1 = encode(64, 64, max_pool=True)\n",
    "        self.down2 = encode(64, 64, max_pool=True)\n",
    "\n",
    "        # skip connections\n",
    "        self.skip1 = skipConn(1, 64, avg_pool=False)\n",
    "        self.skip2 = skipConn(64, 64, avg_pool=True)\n",
    "        self.skip3 = skipConn(64, 64, avg_pool=True)\n",
    "\n",
    "        # decoders\n",
    "        self.up1 = decode(128, 64, 64, up_sample=True)\n",
    "        self.up2 = decode(128, 64, 64, up_sample=True)\n",
    "        self.srgb_out = t.nn.Sequential(\n",
    "            decode(128, 64, 64, up_sample=False),\n",
    "            t.nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            t.nn.Conv2d(64, 3, 3, padding=1))\n",
    "\n",
    "    def forward(self, color_map, mag_map, amp, wb):\n",
    "        # to prevent saturation\n",
    "        mag_map = amp.view(-1, 1, 1, 1) * mag_map\n",
    "        mag_map = t.nn.functional.tanh(mag_map - 0.5)\n",
    "        max_mag = 2.0 * amp.view(-1, 1, 1, 1)\n",
    "        max_mag = t.nn.functional.tanh(max_mag - 0.5)\n",
    "        mag_map = mag_map / max_mag\n",
    "\n",
    "        # encoder outputs\n",
    "        out_head = self.head(t.cat([color_map, mag_map, wb], dim=1))\n",
    "        out_d1 = self.down1(out_head)\n",
    "        out_d2 = self.down2(out_d1)\n",
    "\n",
    "        # skip connection outputs\n",
    "        out_s1 = self.skip1(mag_map)\n",
    "        out_s2 = self.skip2(out_head)\n",
    "        out_s3 = self.skip3(out_d1)\n",
    "\n",
    "        # decoder outputs\n",
    "        out_u1 = self.up1(t.cat([out_s3, out_d2], dim=1))\n",
    "        out_u2 = self.up2(t.cat([out_s2, out_u1], dim=1))\n",
    "        out_srgb = self.srgb_out(t.cat([out_s1, out_u2], dim=1))\n",
    "        out_srgb = t.clamp(out_srgb, 0.0, 1.0)\n",
    "\n",
    "        return out_srgb\n",
    "\n",
    "\n",
    "class rawProcess(BasicModule):\n",
    "    def __init__(self):\n",
    "        super(rawProcess, self).__init__()\n",
    "        self.model_name = 'rawProcess'\n",
    "\n",
    "        # isp module\n",
    "        self.isp_net = ispNet()\n",
    "\n",
    "        # fusion\n",
    "        self.fusion = t.nn.Sequential(t.nn.Conv2d(6, 128, 3, padding=1),\n",
    "                                      channelAtt(128),\n",
    "                                      t.nn.Conv2d(128, 3, 3, padding=1))\n",
    "\n",
    "    def forward(self, raw_data, amp_high, amp_low, wb):\n",
    "        # convert to color map and mgnitude map\n",
    "        mag_map = t.sqrt(t.sum(t.pow(raw_data, 2), 1, keepdim=True))\n",
    "        color_map = raw_data / (mag_map + 1e-4)\n",
    "\n",
    "        # convert to sRGB images\n",
    "        out_high = self.isp_net(color_map, mag_map, amp_high, wb)\n",
    "        out_low = self.isp_net(color_map, mag_map, amp_low, wb)\n",
    "\n",
    "        # image fusion\n",
    "        out_fused = self.fusion(t.cat([out_high, out_low], dim=1))\n",
    "        out_fused = t.clamp(out_fused, 0.0, 1.0)\n",
    "\n",
    "        return out_fused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     13,
     34,
     48,
     158
    ]
   },
   "outputs": [],
   "source": [
    "# normalization\n",
    "def normalize(raw_data, bk_level, sat_level):\n",
    "    normal_raw = t.empty_like(raw_data)\n",
    "    for index in range(raw_data.size(0)):\n",
    "        for channel in range(raw_data.size(1)):\n",
    "            normal_raw[index, channel, :, :] = (\n",
    "                raw_data[index, channel, :, :] -\n",
    "                bk_level[channel]) / (sat_level - bk_level[channel])\n",
    "\n",
    "    return normal_raw\n",
    "\n",
    "\n",
    "# resize Bayer pattern\n",
    "def downSample(raw_data, struct_img_size):\n",
    "    # convert Bayer pattern to down-sized sRGB image\n",
    "    batch, _, hei, wid = raw_data.size()\n",
    "    raw_img = raw_data.new_empty((batch, 3, hei, wid))\n",
    "    raw_img[:, 0, :, :] = raw_data[:, 0, :, :]  # R\n",
    "    raw_img[:,\n",
    "            1, :, :] = (raw_data[:, 1, :, :] + raw_data[:, 2, :, :]) / 2.0  # G\n",
    "    raw_img[:, 2, :, :] = raw_data[:, 3, :, :]  # B\n",
    "\n",
    "    # down-sample to small size\n",
    "    if hei != struct_img_size[1] and wid != struct_img_size[0]:\n",
    "        raw_img = t.nn.functional.interpolate(raw_img,\n",
    "                                              size=(struct_img_size[1],\n",
    "                                                    struct_img_size[0]),\n",
    "                                              mode='bicubic')\n",
    "    raw_img = t.clamp(raw_img, 0.0, 1.0)\n",
    "\n",
    "    return raw_img\n",
    "\n",
    "\n",
    "# image standardization (mean 0, std 1)\n",
    "def standardize(srgb_img):\n",
    "    struct_img = t.empty_like(srgb_img)\n",
    "    adj_std = 1.0 / t.sqrt(srgb_img.new_tensor(srgb_img[0, :, :, :].numel()))\n",
    "    for index in range(srgb_img.size(0)):\n",
    "        mean = t.mean(srgb_img[index, :, :, :])\n",
    "        std = t.std(srgb_img[index, :, :, :])\n",
    "        adj_std = t.max(std, adj_std)\n",
    "        struct_img[index, :, :, :] = (srgb_img[index, :, :, :] -\n",
    "                                      mean) / adj_std\n",
    "\n",
    "    return struct_img\n",
    "\n",
    "\n",
    "# main entry\n",
    "def main(args):\n",
    "    # initialization\n",
    "    att_size = (256, 192)\n",
    "    amp_range = (1, 20)\n",
    "\n",
    "    # choose GPU if available\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "    device = t.device(args.device)\n",
    "\n",
    "    # define models\n",
    "    gain_est_model = gainEst().to(device)\n",
    "    gain_est_model.load('./saves', device=device)\n",
    "    gain_est_model.eval()\n",
    "    raw_process_model = rawProcess().to(device)\n",
    "    raw_process_model.load('./saves', device=device)\n",
    "    raw_process_model.eval()\n",
    "\n",
    "    # search for valid files\n",
    "    file_list = [file for file in os.listdir(args.input) if '.DNG' in file]\n",
    "    file_list.sort()\n",
    "    if not os.path.exists(args.output):\n",
    "        os.makedirs(args.output)\n",
    "\n",
    "    #  loop to process\n",
    "    for file in file_list:\n",
    "        # read black, saturation, and whitebalance\n",
    "        img_md = exiv2.ImageMetadata(os.path.join(args.input, file))\n",
    "        img_md.read()\n",
    "\n",
    "        blk_level = img_md['Exif.SubImage1.BlackLevel'].value\n",
    "        sat_level = img_md['Exif.SubImage1.WhiteLevel'].value\n",
    "        cam_wb = img_md['Exif.Image.AsShotNeutral'].value\n",
    "\n",
    "        # convert flat Bayer pattern to 4D tensor (RGGB)\n",
    "        raw_img = rp.imread(os.path.join(args.input, file))\n",
    "        flat_bayer = raw_img.raw_image_visible\n",
    "        raw_data = np.stack((flat_bayer[0::2, 0::2], flat_bayer[0::2, 1::2],\n",
    "                             flat_bayer[1::2, 0::2], flat_bayer[1::2, 1::2]),\n",
    "                            axis=2)\n",
    "\n",
    "        with t.no_grad():\n",
    "            # copy to device\n",
    "            blk_level = t.from_numpy(np.array(blk_level,\n",
    "                                              dtype=np.float32)).to(device)\n",
    "            sat_level = t.from_numpy(np.array(sat_level,\n",
    "                                              dtype=np.float32)).to(device)\n",
    "            cam_wb = t.from_numpy(np.array(cam_wb,\n",
    "                                           dtype=np.float32)).to(device)\n",
    "            raw_data = t.from_numpy(raw_data.astype(np.float32)).to(device)\n",
    "            raw_data = raw_data.permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "            # downsample\n",
    "            if args.resize:\n",
    "                raw_data = t.nn.functional.interpolate(raw_data,\n",
    "                                                       size=args.resize,\n",
    "                                                       mode='bicubic')\n",
    "\n",
    "            # pre-processing\n",
    "            raw_data = normalize(raw_data, blk_level, sat_level)\n",
    "            cam_wb = cam_wb.view([1, 3, 1, 1]).expand(\n",
    "                [1, 3, raw_data.size(2),\n",
    "                 raw_data.size(3)])\n",
    "            cam_wb = cam_wb.clone()\n",
    "            thumb_img = downSample(raw_data, att_size)\n",
    "            struct_img = standardize(thumb_img)\n",
    "\n",
    "            # run model\n",
    "            _, pred_amp = gain_est_model(thumb_img, struct_img)\n",
    "            pred_amp = t.clamp(pred_amp * amp_range[1], amp_range[0],\n",
    "                               amp_range[1])\n",
    "            print('Predicted ratio(fg/bg) for %s: %.2f, %.2f.' %\n",
    "                  (file, pred_amp[0, 0], pred_amp[0, 1]))\n",
    "            amp_high, _ = t.max(pred_amp, 1)\n",
    "            amp_low, _ = t.min(pred_amp, 1)\n",
    "            pred_fused = raw_process_model(raw_data, amp_high, amp_low, cam_wb)\n",
    "\n",
    "        # save to images\n",
    "        save_image(\n",
    "            pred_fused.cpu().squeeze(),\n",
    "            os.path.join(args.output,\n",
    "                         '%s' % file.replace('.DNG', '-fuse.png')))\n",
    "\n",
    "        # fisheye lens calibration\n",
    "        # modified from https://medium.com/@kennethjiang/calibrate-fisheye-lens-using-opencv-333b05afa0b0\n",
    "        if args.calib:\n",
    "            import cv2\n",
    "\n",
    "            DIM = (4000, 3000)\n",
    "            K = np.array([[1715.9053454852321, 0.0, 2025.0267134780845],\n",
    "                          [0.0, 1713.8092418955127, 1511.2242172068645],\n",
    "                          [0.0, 0.0, 1.0]])\n",
    "            D = np.array([[0.21801544244553403], [0.011549797903321477],\n",
    "                          [-0.05436236262851618], [-0.01888678272481524]])\n",
    "            img = cv2.imread(\n",
    "                os.path.join(args.output,\n",
    "                             '%s' % file.replace('.DNG', '-fuse.png')))\n",
    "            map1, map2 = cv2.fisheye.initUndistortRectifyMap(\n",
    "                K, D, np.eye(3), K, DIM, cv2.CV_16SC2)\n",
    "            calib_img = cv2.remap(img,\n",
    "                                  map1,\n",
    "                                  map2,\n",
    "                                  interpolation=cv2.INTER_LINEAR,\n",
    "                                  borderMode=cv2.BORDER_CONSTANT)\n",
    "            cv2.imwrite(\n",
    "                os.path.join(args.output,\n",
    "                             '%s' % file.replace('.DNG', '-calib.png')),\n",
    "                calib_img)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--input', default='./samples', help='input directory')\n",
    "    parser.add_argument('--output',\n",
    "                        default='./results',\n",
    "                        help='output directory')\n",
    "    parser.add_argument('--resize',\n",
    "                        default=None,\n",
    "                        type=tuple,\n",
    "                        help='downsample to smaller size (hxw)')\n",
    "    parser.add_argument('--device',\n",
    "                        default='cpu',\n",
    "                        help='device to be used (cpu or cuda)')\n",
    "    parser.add_argument('--calib',\n",
    "                        action='store_true',\n",
    "                        help='perform fisheye calibration')\n",
    "    args = parser.parse_args()\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
