{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# mass includes\n",
    "import os\n",
    "import pickle\n",
    "import pyexiv2 as exiv2\n",
    "import rawpy as rp\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from rawpy import HighlightMode\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# configuration\n",
    "data_root = '/home/lab/Documents/ssd/DJI'  # dataset path\n",
    "save_root = '/home/lab/Documents/ssd/r2rSet'  # save path\n",
    "file_ext = '.DNG'  # extension of raw file\n",
    "train_num = 710  # num of images for training\n",
    "patch_size = (400, 300)  # size of each patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAW data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# get file list\n",
    "file_list = [file for file in os.listdir(data_root) if file_ext in file]\n",
    "file_list.sort()\n",
    "\n",
    "# make new folders\n",
    "train_path = os.path.join(save_root, 'train')\n",
    "os.makedirs(train_path)\n",
    "val_path = os.path.join(save_root, 'val')\n",
    "os.makedirs(val_path)\n",
    "\n",
    "for index, file in tqdm(enumerate(file_list),\n",
    "                        desc='progress',\n",
    "                        total=len(file_list)):\n",
    "    # find black, saturation, and whitebalance\n",
    "    img_md = exiv2.ImageMetadata(os.path.join(data_root, file))\n",
    "    img_md.read()\n",
    "\n",
    "    blk_level = img_md['Exif.SubImage1.BlackLevel'].value\n",
    "    sat_level = img_md['Exif.SubImage1.WhiteLevel'].value\n",
    "    cam_wb = img_md['Exif.Image.AsShotNeutral'].value\n",
    "\n",
    "    # convert flat Bayer pattern to 4D tensor (RGGB)\n",
    "    raw_img = rp.imread(os.path.join(data_root, file))\n",
    "    flat_bayer = raw_img.raw_image_visible\n",
    "    raw_data = np.stack((flat_bayer[0::2, 0::2], flat_bayer[0::2, 1::2],\n",
    "                         flat_bayer[1::2, 0::2], flat_bayer[1::2, 1::2]),\n",
    "                        axis=2)\n",
    "\n",
    "    # get ground-truth sRGB image\n",
    "    gt_img = raw_img.postprocess(use_camera_wb=True,\n",
    "                                 output_bps=16,\n",
    "                                 no_auto_bright=True,\n",
    "                                 adjust_maximum_thr=0.0,\n",
    "                                 highlight_mode=HighlightMode.Ignore)\n",
    "\n",
    "    # split to small patches\n",
    "    part_idx = 0\n",
    "    raw_hei = gt_img.shape[0] / 2\n",
    "    raw_wid = gt_img.shape[1] / 2\n",
    "    for i in range(0, int(raw_hei / patch_size[1])):\n",
    "        for j in range(0, int(raw_wid / patch_size[0])):\n",
    "            crop_h = i * patch_size[1]\n",
    "            crop_w = j * patch_size[0]\n",
    "            raw_patch = raw_data[crop_h:crop_h + patch_size[1],\n",
    "                                 crop_w:crop_w + patch_size[0], :]\n",
    "            gt_patch = gt_img[2 * crop_h:2 * (crop_h + patch_size[1]),\n",
    "                              2 * crop_w:2 * (crop_w + patch_size[0]), :]\n",
    "\n",
    "            # save to files\n",
    "            patch = {}\n",
    "            patch['blk_level'] = np.array(blk_level, dtype=np.uint16)\n",
    "            patch['sat_level'] = np.array(sat_level, dtype=np.uint16)\n",
    "            patch['cam_wb'] = np.array(cam_wb, dtype=np.float32)\n",
    "            patch['raw'] = np.transpose(raw_patch, (2, 0, 1))\n",
    "            patch['img'] = np.transpose(gt_patch, (2, 0, 1))\n",
    "            if index < train_num:\n",
    "                file_path = os.path.join(\n",
    "                    train_path, '%s_p%03d.pkl' % (file[:-4], part_idx))\n",
    "            else:\n",
    "                file_path = os.path.join(\n",
    "                    val_path, '%s_p%03d.pkl' % (file[:-4], part_idx))\n",
    "            with open(file_path, 'wb') as pkl_file:\n",
    "                pickle.dump(patch, pkl_file)\n",
    "\n",
    "            # update part index\n",
    "            part_idx += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
